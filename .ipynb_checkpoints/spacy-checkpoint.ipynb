{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spacy test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import neccesary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.matcher import Matcher\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.models import KeyedVectors\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pre-trained corpus to help tokenise words\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In NLP \n",
    "Document -> a bunch of texts <br>\n",
    "Corpus -> a bunch of documents <br>\n",
    "Vectors -> a mathematically convenience representation of a document (a bunch of textx) <br>\n",
    "Models -> an algorithm for transforming vectors from one representation to another <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie = pd.read_csv('nMovieRg.csv', usecols=['title','description'])\n",
    "tvshow = pd.read_csv('nTvshowRg.csv', usecols=['title','description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_df = movie.append(tvshow, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Each description is a \"doc\". The collection of these \"docs\" is the \"corpus\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = net_originals.description.values.tolist() #list of docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenise(doc):\n",
    "    return [token.text for token in nlp(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_corpus = [tokenise(doc) for doc in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_text = dict(zip(net_originals['title'].str.lower().tolist(), token_corpus))\n",
    "# lower the title (easy for search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"GoogleNews-vectors-negative300.bin\"\n",
    "w2v = KeyedVectors.load_word2vec_format(path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(first_map, second_map):\n",
    "    first_vec  = dict()\n",
    "    for uid, content in first_map.items():\n",
    "        temp = list()\n",
    "        for element in content:\n",
    "            try:\n",
    "                temp.append(second_map[element])\n",
    "            except KeyError:\n",
    "                pass\n",
    "        first_vec[uid] = np.mean(temp, axis=0)\n",
    "    \n",
    "    return first_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_similar(lookup_id, title_vec):\n",
    "\n",
    "    sim = list()\n",
    "    lookup_map = title_vec\n",
    "    subject_map = title_vec \n",
    "        \n",
    "    for uid, vec in lookup_map.items():\n",
    "        thisSim = cosine_similarity(vec.reshape(1, -1), subject_map[lookup_id].reshape(1, -1))\n",
    "        sim.append((uid, thisSim[0][0]))\n",
    "\n",
    "    return sorted(sim, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_vec = get_vectors(title_text, w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_most_similar('house of cards', title_vec)[1:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_most_similar('black mirror', title_vec)[1:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "似乎是沒有很準 現在來試試看 6k dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## same approach but with 6k dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data6k = pd.read_csv('netflixMovieDb.csv')\n",
    "data6k = data6k.append(pd.read_csv('netflixTvshowDb.csv')).append(pd.read_csv('dMoviesDb.csv')).append(pd.read_csv('dTvshowsDb.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data6k.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = list()\n",
    "for ix in range(data6k.shape[0]):\n",
    "    content = list()\n",
    "    for e in data6k.iloc[ix,5:9]:\n",
    "        content.append(str(e))\n",
    "    s = ','.join(content)\n",
    "    ls.append(s)\n",
    "    \n",
    "data6k['everything'] = ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus6k = data6k.description.values.tolist() #list of docs\n",
    "token_corpus6k = [tokenise(doc) for doc in corpus6k]\n",
    "title_text = dict(zip(data6k['title'].str.lower().tolist(), token_corpus6k))\n",
    "# lower the title (easy for search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_vec6k = get_vectors(title_text, w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"house of cards\"\n",
    "sim = get_most_similar(title, title_vec6k)[1:11]\n",
    "pprint(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_title_description(title, dataset):\n",
    "    \"\"\"Return the title description\"\"\"\n",
    "    filt = dataset['title'].str.lower() == title\n",
    "    return dataset.loc[filt]['description'].values.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dscp_comparison(org, dataset, vec):\n",
    "    \n",
    "    org = org.lower()\n",
    "    org_dscp = dataset.loc[dataset['title'].str.lower() == org]['description'].values.tolist()[0]\n",
    "    print(f\"The input title name is '{org}'\\n\")\n",
    "    print(org_dscp, '\\n')\n",
    "    sim = get_most_similar(org, vec)[1:11]\n",
    "    \n",
    "    for i in range(len(sim)):\n",
    "        title = sim[i][0]\n",
    "        print(f\"The most similiar No.{i+1} is '{title}'\\n\")\n",
    "        print(sim_title_description(title, dataset),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Star Wars: The Rise of Skywalker (Episode IX)\".lower()\n",
    "dscp_comparison(title, data6k, title_vec6k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = (\"Star Wars: The Rise of Skywalker (Episode IX)\").lower()\n",
    "sim = get_most_similar(title, title_vec6k)[1:11]\n",
    "pprint(sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 看起來迪士尼電影的預測蠻準的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "現在來試試看把genres也加進去會如何"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus6k_everything = data6k.everything.values.tolist() #list of docs\n",
    "token_corpus6k_eve = [tokenise(doc) for doc in corpus6k_everything]\n",
    "title_text_eve = dict(zip(data6k['title'].str.lower().tolist(), token_corpus6k_eve))\n",
    "# lower the title (easy for search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_vec6k_eve = get_vectors(title_text_eve, w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = (\"Star Wars: The Rise of Skywalker (Episode IX)\").lower()\n",
    "sim = get_most_similar(title, title_vec6k_eve)[1:11]\n",
    "pprint(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = (\"house of cards\").lower()\n",
    "sim = get_most_similar(title, title_vec6k_eve)[1:11]\n",
    "pprint(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = (\"ONE PIECE\").lower()\n",
    "sim = get_most_similar(title, title_vec6k_eve)[1:11]\n",
    "pprint(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = (\"our planet\").lower()\n",
    "sim = get_most_similar(title, title_vec6k_eve)[1:11]\n",
    "pprint(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = (\"Avatar: The Last Airbender\").lower()\n",
    "sim = get_most_similar(title, title_vec6k_eve)[1:11]\n",
    "pprint(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = (\"One-punch man\").lower()\n",
    "sim = get_most_similar(title, title_vec6k_eve)[1:11]\n",
    "pprint(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = (\"world war II in colour\").lower()\n",
    "sim = get_most_similar(title, title_vec6k_eve)[1:11]\n",
    "pprint(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = (\"chef's table\").lower()\n",
    "print(dscp_comparison(title, data6k, title_vec6k_eve))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 如果用Netflix all-info 會如何？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_originals.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = list()\n",
    "for ix in range(net_originals.shape[0]):\n",
    "    content = list()\n",
    "    for e in net_originals.iloc[ix,5:9]:\n",
    "        content.append(str(e))\n",
    "    s = ','.join(content)\n",
    "    ls.append(s)\n",
    "    \n",
    "net_originals['everything'] = ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_netall= net_originals.everything.values.tolist() #list of docs\n",
    "token_corpus_netall = [tokenise(doc) for doc in corpus_netall]\n",
    "title_text_netall = dict(zip(net_originals['title'].str.lower().tolist(), token_corpus_netall))\n",
    "# lower the title (easy for search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_vec6k_netall = get_vectors(title_text_netall, w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = (\"marvel's daredevil\").lower()\n",
    "sim = get_most_similar(title, title_vec6k_netall)[1:11]\n",
    "pprint(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = (\"marvel's daredevil\").lower()\n",
    "print(dscp_comparison(title, data6k, title_vec6k_netall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test out wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not good at all Don't use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display scatterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "def display_pca_scatterplot(titles, vec):\n",
    "    \n",
    "    title_vectors = np.array([vec[title] for title in titles])\n",
    "    twodim = PCA().fit_transform(title_vectors)[:,:2]\n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.scatter(twodim[:,0], twodim[:,1], edgecolors='k', c='r')\n",
    "    for title, (x,y) in zip(titles, twodim):\n",
    "        plt.text(x+0.05, y+0.05, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = np.random.choice(data6k['title'].values, size = 10).tolist()\n",
    "titles = [title.lower() for title in titles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_pca_scatterplot(titles, title_vec6k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
