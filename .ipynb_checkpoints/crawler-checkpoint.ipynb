{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re, requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from time import sleep\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create crawler class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class crawler:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialise the crawler\"\"\"\n",
    "        self.driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "        \n",
    "    def get_page(self,url):\n",
    "        driver = self.driver\n",
    "        driver.get(url)\n",
    "    \n",
    "    def scroll_down(self):\n",
    "        driver = self.driver\n",
    "        \n",
    "        sleep(0.5)\n",
    "        for i in range(20): \n",
    "            driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "            sleep(0.6)\n",
    "    \n",
    "    def get_page_source(self):\n",
    "        driver = self.driver\n",
    "        return driver.page_source\n",
    "    \n",
    "    def get_title_links(self):\n",
    "        driver = self.driver\n",
    "        s = driver.page_source\n",
    "        soup = BeautifulSoup(s, 'html.parser')\n",
    "        source_titles = soup.findAll('a',{'class':'title'})\n",
    "        links = [title['href'] for title in source_titles]\n",
    "        return links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "movies first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flixable(content_type):\n",
    "    \"\"\"This function will return a flixable url with parameters set\"\"\"\n",
    "    required_type = ['tv-shows','movies']\n",
    "    if content_type in required_type:\n",
    "        headers = {\n",
    "                    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.129 Safari/537.36\"}\n",
    "\n",
    "        url = f'https://flixable.com/netflix-originals/genre/{content_type}/#filterContainer'\n",
    "        my_parameters = {'min-rating':0, 'min-year':1920, 'max-year':2019, 'order':'title'}\n",
    "\n",
    "        re_url = requests.get(url , my_parameters,headers = headers).url\n",
    "        return re_url\n",
    "    \n",
    "    else:\n",
    "        print('KeyError. Please enter either tv-shows or movies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Current google-chrome version is 83.0.4103\n",
      "[WDM] - Get LATEST driver version for 83.0.4103\n",
      "[WDM] - Driver [/Users/hsichengyun/.wdm/drivers/chromedriver/mac64/83.0.4103.39/chromedriver] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    }
   ],
   "source": [
    "crawler = crawler()\n",
    "url = flixable('tv-shows')\n",
    "crawler.get_page(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get title links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser(url):\n",
    "    \"\"\"Return bs4 object\"\"\"\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.129 Safari/537.36\"}\n",
    "    r = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    return soup\n",
    "\n",
    "def get_info(content_type, links):\n",
    "    DF = pd.DataFrame(columns=['title', 'type', 'release_year', 'rating', \n",
    "                               'runtime', 'description', 'genres', 'cast',\n",
    "                               'director', 'country', 'imdb_link', 'date_added'])\n",
    "    for ix in range(len(links)):\n",
    "        full_url = 'https://flixable.com' + links[ix]\n",
    "        r = requests.get(full_url)\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        \n",
    "        title = soup.find('h1').text\n",
    "        release_year = soup.find('div',{'class':'col-lg-8'}).find('h6').findAll('span')[0].text\n",
    "        rating = soup.find('div',{'class':'col-lg-8'}).find('h6').findAll('span')[1].text\n",
    "        runtime = soup.find('div',{'class':'col-lg-8'}).find('h6').findAll('span')[2].text\n",
    "        description = soup.find('p',{'class':'card-description'}).text\n",
    "        tag_a = soup.find('div',{'class':'col-lg-8'}).findAll('a')\n",
    "        genres = list()\n",
    "        cast = list()\n",
    "        director = list()\n",
    "        country = list()\n",
    "        imdb_link = list()\n",
    "        for a in tag_a:\n",
    "            if 'genre' in a['href']:\n",
    "                genres.append(a.text)\n",
    "\n",
    "            elif 'director' in a['href']:\n",
    "                director.append(a.text)\n",
    "\n",
    "            elif 'actor' in a['href']:\n",
    "                cast.append(a.text)\n",
    "\n",
    "            elif 'country' in a['href']:\n",
    "                country.append(a.text)\n",
    "\n",
    "            elif 'www.imdb.com' in a['href']:\n",
    "                imdb_link.append(a['href'])\n",
    "        date_added = soup.find('div',{'class':'col-lg-8'}).findAll('p')[-1].text.lstrip().rstrip()\n",
    "        \n",
    "        sep = ','\n",
    "        \n",
    "        df = pd.DataFrame(columns=['title', 'type', 'release_year', 'rating', \n",
    "                                   'runtime', 'description', 'genres', 'cast',\n",
    "                                   'director', 'country', 'imdb_link', 'date_added'],\n",
    "                         data = [{\n",
    "                             'title': title,\n",
    "                             'type': content_type,\n",
    "                             'release_year': release_year,\n",
    "                             'rating': rating,\n",
    "                             'runtime': runtime,\n",
    "                             'description': description,\n",
    "                             'genres': sep.join(genres),\n",
    "                             'cast': sep.join(cast),\n",
    "                             'director': sep.join(director),\n",
    "                             'country': sep.join(country),\n",
    "                             'imdb_link': sep.join(imdb_link),\n",
    "                             'date_added': date_added\n",
    "                         }])\n",
    "        DF = DF.append(df, ignore_index=True)\n",
    "        \n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie_links = crawler.get_title_links()\n",
    "# movie_db = get_info('movies',movie_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = movie_db.append(tvshow_db, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-270.80918653396657\n"
     ]
    }
   ],
   "source": [
    "# start = timeit.default_timer()\n",
    "# tvshow_links = crawler.get_title_links()\n",
    "# tvshow_db = get_info('tvshow', tvshow_links)\n",
    "# end = timeit.default_timer()\n",
    "# print(start-end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rv_votes(dataset):\n",
    "    start = timeit.default_timer()\n",
    "    rating_value = list()\n",
    "    votes = list()\n",
    "    count = 1\n",
    "    for link in dataset['imdb_link']:\n",
    "        if count == 100 or count == 300 or count == 500 or count == 700 or count == 900 or count == 1200 or count == 1400:\n",
    "            print(count)\n",
    "        count += 1\n",
    "        try:\n",
    "            soup = parser(link)\n",
    "            ratingValue = soup.find('span', {'itemprop':'ratingValue'}).text\n",
    "            ratingCount = soup.find('span', {'itemprop':'ratingCount'}).text\n",
    "            rating_value.append(ratingValue)\n",
    "            votes.append(ratingCount)\n",
    "        except:\n",
    "            rating_value.append('NaN')\n",
    "            votes.append('NaN')\n",
    "        \n",
    "    stop = timeit.default_timer()\n",
    "    t = int(stop-start)\n",
    "    print(f\"It took {t} minutes to scrape rating values and votes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
