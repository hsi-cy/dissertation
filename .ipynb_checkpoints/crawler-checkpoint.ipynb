{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re, requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create crawler class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class crawler:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialise the crawler\"\"\"\n",
    "        self.driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "        \n",
    "    def get_page(self,url):\n",
    "        driver = self.driver\n",
    "        driver.get(url)\n",
    "    \n",
    "    def scroll_down(self):\n",
    "        driver = self.driver\n",
    "        \n",
    "        sleep(0.5)\n",
    "        for i in range(20): \n",
    "            driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "            sleep(0.6)\n",
    "    \n",
    "    def get_page_source(self):\n",
    "        driver = self.driver\n",
    "        return driver.page_source\n",
    "    \n",
    "    def get_title_links(self):\n",
    "        driver = self.driver\n",
    "        s = driver.page_source\n",
    "        soup = BeautifulSoup(s, 'html.parser')\n",
    "        source_titles = soup.findAll('a',{'class':'title'})\n",
    "        links = [title['href'] for title in source_titles]\n",
    "        return links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "movies first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.129 Safari/537.36\"}\n",
    "\n",
    "tv_shows = 'tv-shows'\n",
    "movies = 'movies'\n",
    "\n",
    "url = f'https://flixable.com/netflix-originals/genre/{movies}/#filterContainer'\n",
    "my_parameters = {'min-rating':0, 'min-year':1920, 'max-year':2019, 'order':'title'}\n",
    "\n",
    "re_url = requests.get(url , my_parameters,headers = headers).url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Current google-chrome version is 83.0.4103\n",
      "[WDM] - Get LATEST driver version for 83.0.4103\n",
      "[WDM] - Driver [/Users/hsichengyun/.wdm/drivers/chromedriver/mac64/83.0.4103.39/chromedriver] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    }
   ],
   "source": [
    "crawler = crawler()\n",
    "crawler.get_page(re_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get title links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_links = crawler.get_title_links()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(content_type, links, dataset):\n",
    "    DF = pd.DataFrame()\n",
    "    for ix in range(len(links)):\n",
    "        full_url = 'https://flixable.com' + links[ix]\n",
    "        r = requests.get(full_url)\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        \n",
    "        title = soup.find('h1').text\n",
    "        release_year = soup.find('div',{'class':'col-lg-8'}).find('h6').findAll('span')[0].text\n",
    "        rating = soup.find('div',{'class':'col-lg-8'}).find('h6').findAll('span')[1].text\n",
    "        runtime = soup.find('div',{'class':'col-lg-8'}).find('h6').findAll('span')[2].text\n",
    "        description = soup.find('p',{'class':'card-description'}).text\n",
    "        tag_a = soup.find('div',{'class':'col-lg-8'}).findAll('a')\n",
    "        genres = list()\n",
    "        cast = list()\n",
    "        director = list()\n",
    "        country = list()\n",
    "        imdb_link = list()\n",
    "        for a in tag_a:\n",
    "            if 'genre' in a['href']:\n",
    "                genres.append(a.text)\n",
    "\n",
    "            elif 'director' in a['href']:\n",
    "                director.append(a.text)\n",
    "\n",
    "            elif 'actor' in a['href']:\n",
    "                cast.append(a.text)\n",
    "\n",
    "            elif 'country' in a['href']:\n",
    "                country.append(a.text)\n",
    "\n",
    "            elif 'www.imdb.com' in a['href']:\n",
    "                imdb_link.append(a['href'])\n",
    "        date_added = soup.find('div',{'class':'col-lg-8'}).findAll('p')[-1].text.lstrip().rstrip()\n",
    "        \n",
    "        \n",
    "        df = pd.DataFrame(columns=['title', 'type', 'release_year', 'rating', \n",
    "                                   'runtime', 'description', 'genres', 'cast',\n",
    "                                   'director', 'country', 'imdb_link', 'date_added'],\n",
    "                         data = [{\n",
    "                             'title': title,\n",
    "                             'type': content_type,\n",
    "                             'release_year': release_year,\n",
    "                             'rating': rating,\n",
    "                             'runtime': runtime,\n",
    "                             'description': description,\n",
    "                             'genres': genres,\n",
    "                             'cast': cast,\n",
    "                             'director': director,\n",
    "                             'country': country,\n",
    "                             'imdb_link': imdb_link,\n",
    "                             'date_added': date_added\n",
    "                         }])\n",
    "        DF.append(df, ignore_index=True)\n",
    "        \n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_url = 'https://flixable.com' + movie_links[0]\n",
    "r = requests.get(full_url)\n",
    "soup = BeautifulSoup(r.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_row = soup.find('div',{'class':'col-lg-8'}).find('h6').findAll('span')\n",
    "release_year, movie_rating, movie_runtime = first_row[0].text, first_row[1].text, first_row[2].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When nerdy high schooler Dani finally attracts the interest of her longtime crush, she lands in the cross hairs of his ex, a social media celebrity.\n"
     ]
    }
   ],
   "source": [
    "movie_dscp = soup.find('p',{'class':'card-description'}).text\n",
    "print(movie_dscp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_a = soup.find('div',{'class':'col-lg-8'}).findAll('a')\n",
    "genres = list()\n",
    "cast = list()\n",
    "director = list()\n",
    "country = list()\n",
    "imdb_link = list()\n",
    "for a in tag_a:\n",
    "    if 'genre' in a['href']:\n",
    "        genres.append(a.text)\n",
    "        \n",
    "    elif 'director' in a['href']:\n",
    "        director.append(a.text)\n",
    "    \n",
    "    elif 'actor' in a['href']:\n",
    "        cast.append(a.text)\n",
    "        \n",
    "    elif 'country' in a['href']:\n",
    "        country.append(a.text)\n",
    "    \n",
    "    elif 'www.imdb.com' in a['href']:\n",
    "        imdb_link.append(a['href'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added to Netflix:September 8, 2017\n"
     ]
    }
   ],
   "source": [
    "date_added = soup.find('div',{'class':'col-lg-8'}).findAll('p')[-1].text.lstrip().rstrip()\n",
    "print(date_added)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "soup.find('div',{'class':'col-lg-8'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_titles = list()\n",
    "for ix in range(len(links)):\n",
    "    full_url = 'https://flixable.com' + links[ix]\n",
    "    r = requests.get(full_url)\n",
    "    s = BeautifulSoup(r.text, 'html.parser')\n",
    "    tv_titles.append(s.find('h1').text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame()\n",
    "dataset['tvshow_title'] = tv_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f'https://flixable.com/netflix-originalzzs/genre/{movies}/#filterContainer'\n",
    "my_parameters = {'min-rating':0, 'min-year':1920, 'max-year':2019, 'order':'title'}\n",
    "\n",
    "re_url = requests.get(url , my_parameters,headers = headers).url\n",
    "crawler.get_page(re_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = crawler.get_page_source()\n",
    "soup = BeautifulSoup(s, 'html.parser')\n",
    "source_titles = soup.findAll('a',{'class':'title'})\n",
    "print(len(source_titles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = list()\n",
    "for title in source_titles:\n",
    "    links.append(title['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_titles = list()\n",
    "for ix in range(len(links)):\n",
    "    full_url = 'https://flixable.com' + links[ix]\n",
    "    r = requests.get(full_url)\n",
    "    s = BeautifulSoup(r.text, 'html.parser')\n",
    "    movie_titles.append(s.find('h1').text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['movie_title'] = movie_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('movie_title.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
