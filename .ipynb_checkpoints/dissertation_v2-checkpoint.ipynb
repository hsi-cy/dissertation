{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "from gensim.models import KeyedVectors, Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "SPECIAL_CHARS = '[^A-Za-z0-9 ]+'\n",
    "STOP_WORDS = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Take out stopwords.\n",
    "    Take out punctuations and special characters.\n",
    "    \"\"\"\n",
    "    SPECIAL_CHARS = '[^A-Za-z0-9 ]+'\n",
    "    STOP_WORDS = stopwords.words('english')\n",
    "    text = text.lower().split(' ')\n",
    "    temp = [word for word in text if word not in STOP_WORDS]\n",
    "    text = ' '.join(temp)\n",
    "    text = re.sub(SPECIAL_CHARS, '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenise(doc):\n",
    "    return [token.text for token in nlp(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenise_lemma(doc):\n",
    "    \"\"\"\n",
    "    Use spacy as the nlp object to tokenise each doc\n",
    "    Lemmatise each words\n",
    "    \"\"\"\n",
    "    return ' '.join([token.lemma_ for token in nlp(doc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is one way to get each title's vector representation\n",
    "# more investagtion is needed later.\n",
    "\n",
    "def get_vectors(first_map, second_map):\n",
    "    \"\"\"\n",
    "    Use tokenised words to get vectors representations from the pretrained model (i.e. second_map).\n",
    "    Average the vector representation of the description as the representation of the document \n",
    "    (i.e. each movie title's representation is the mean of vectors of each words in its description)\n",
    "    \"\"\"\n",
    "    first_vec  = dict()\n",
    "    for title, description in first_map.items():\n",
    "        temp = list()\n",
    "        for element in description: #element = tokenised words\n",
    "            try:\n",
    "                temp.append(second_map[element]) #secondmap is w2v model which should have a responding word vecotr for the tokenise word\n",
    "            except KeyError:\n",
    "                pass\n",
    "        first_vec[title] = np.mean(temp, axis=0)\n",
    "    \n",
    "    return first_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(name, df):\n",
    "    return df.loc[df['title'].str.lower()==name.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topN_similar(lookup_id, title_vec, df, N=10):\n",
    "    lookup_id = lookup_id.lower()\n",
    "    sim = list()\n",
    "    lookup_map = title_vec\n",
    "    subject_map = title_vec \n",
    "        \n",
    "    for uid, vec in lookup_map.items():\n",
    "        thisSim = cosine_similarity(vec.reshape(1, -1), subject_map[lookup_id].reshape(1, -1))\n",
    "        org = search(uid, df).originals.values\n",
    "        gen = search(uid, df).genres.values\n",
    "        sim.append((uid, thisSim[0][0], org, gen))\n",
    "    sim = sorted(sim, key=lambda x: x[1], reverse=True)[:N+1]\n",
    "    returnDf = pd.DataFrame(columns=['title','similarity','originals','genres'],\n",
    "                           data = sim)\n",
    "    return returnDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_similar(lookup_id, title_vec, df):\n",
    "\n",
    "    sim = list()\n",
    "    lookup_map = title_vec\n",
    "    subject_map = title_vec \n",
    "        \n",
    "    for uid, vec in lookup_map.items():\n",
    "        thisSim = cosine_similarity(vec.reshape(1, -1), subject_map[lookup_id].reshape(1, -1))\n",
    "        org = search(uid, df).originals.values\n",
    "        gen = search(uid, df).genres.values\n",
    "        sim.append((uid, thisSim[0][0], org, gen))\n",
    "\n",
    "    return sorted(sim, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df(keyword):\n",
    "    \"\"\"\n",
    "    Return a dataframe with the filtered result.\n",
    "    The input value is case-insensitive. \n",
    "    \"\"\"\n",
    "    if type(keyword) == list:\n",
    "        return netflixDf.loc[netflixDf['title'].isin(keyword)]\n",
    "    else:\n",
    "        return netflixDf.loc[netflixDf['title'].str.lower().isin([keyword.lower()])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def markerX(key, values):\n",
    "    return netflixDf.loc[netflixDf[key].str.lower().isin(values)].sort_values(by='pca_2', ascending=False)\n",
    "\n",
    "def others(key, values):\n",
    "    return netflixDf.loc[~netflixDf[key].str.lower().isin(values)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Analyse Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terms explained\n",
    "Document -> a bunch of texts <br>\n",
    "Corpus -> a bunch of documents <br>\n",
    "Vectors -> a mathematically convenience representation of a document (a bunch of textx) <br>\n",
    "Models -> an algorithm for transforming vectors from one representation to another <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the dataset/ Load the spacy pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# netflixDf = pd.read_csv('finalDataset_v3.csv', usecols=['title','type','description','genres','originals', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('debugged.csv', usecols=['cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# netflixDf = pd.concat([netflixDf,df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.where(pd.isnull(df.cleaned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pre-trained corpus to help tokenise words\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse Descriptive Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieDf = pd.read_csv('movie_dataset_july18.csv', usecols=['title','genres','year','type','originals','everything'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Corpus and apply word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'title', 'genres', 'year', 'type', 'originals',\n",
       "       'description', 'everything'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movieDf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieTkDocs = [tokenise(doc) for doc in movieDf.everything.values.tolist()] #tokenise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping out the title and each description. so later on i can search \n",
    "movieMap = dict(zip(movieDf['title'].str.lower().tolist(), movieTkDocs))\n",
    "# lower the title (easy for search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"GoogleNews-vectors-negative300.bin\"\n",
    "w2v = KeyedVectors.load_word2vec_format(path, binary=True)\n",
    "# It is much faster take less than 2 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieTitleVec = get_vectors(movieMap, w2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What if I include genre information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieDf_gen = netflixDf.loc[netflixDf['type']=='movie'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# netflixDf['genres'].fillna('No info', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "for i in netflixDf.year.values.tolist():\n",
    "    if len(i)==4:\n",
    "        y.append(i)\n",
    "    else:\n",
    "        y.append('No info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflixDf['year'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# netflixDf.to_csv('finaldataset_v3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_csv('finaldataset_v3.csv', usecols=['title','genres','year','type','originals','cleaned'])\n",
    "mvevt = temp.loc[temp['type']=='movie'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvevt.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "everything = list()\n",
    "for ix in range(3770):\n",
    "    everything.append(mvevt.iloc[ix,5]+ ' ' +mvevt.iloc[ix,1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvevt['everything'] = everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvevt.rename(columns={'cleaned':'description'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvevtTkDocs = [tokenise(doc) for doc in mvevt.everything.values.tolist()] #tokenise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping out the title and each description. so later on i can search \n",
    "movieMap = dict(zip(mvevt['title'].str.lower().tolist(), mvevtTkDocs))\n",
    "# lower the title (easy for search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieTitleVec = get_vectors(movieMap, w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_topN_similar('tall girl', movieTitleVec, mvevt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search('social animals',movieDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_topN_similar('bird box', movieTitleVec, mvevt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search('mute', movieDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It is clear that adding genres into corpus improves accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genres count\n",
    "mv = temp.loc[temp['type']=='movie'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_genres(genre_list):\n",
    "    \"\"\"\n",
    "    genre_list is pd sereis\n",
    "    return a dataframe\n",
    "    \"\"\"\n",
    "    genres_count = defaultdict(int)\n",
    "    for movie in genre_list:\n",
    "        for genre in movie.split(','):\n",
    "            genres_count[genre] += 1\n",
    "    df = pd.DataFrame(data=[genres_count])\n",
    "    df = df.transpose().reset_index().rename(columns={'index':'genres',0:'counts'}).sort_values(by = 'counts', ascending=False).reset_index(drop=True)\n",
    "    df['percentage'] = df['counts'].apply(lambda x: round(x/df.counts.sum(),2))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_values_on_bars(axs, h_v=\"v\", space=0.4):\n",
    "    def _show_on_single_plot(ax):\n",
    "        if h_v == \"v\":\n",
    "            for p in ax.patches:\n",
    "                _x = p.get_x() + p.get_width() / 2\n",
    "                _y = p.get_y() + p.get_height()\n",
    "                value = int(p.get_height())\n",
    "                ax.text(_x, _y, value, ha=\"center\") \n",
    "        elif h_v == \"h\":\n",
    "            for p in ax.patches:\n",
    "                _x = p.get_x() + p.get_width() + float(space)\n",
    "                _y = p.get_y() + p.get_height()\n",
    "                value = int(p.get_width())\n",
    "                ax.text(_x, _y, value, ha=\"left\", va='bottom')\n",
    "\n",
    "    if isinstance(axs, np.ndarray):\n",
    "        for idx, ax in np.ndenumerate(axs):\n",
    "            _show_on_single_plot(ax)\n",
    "    else:\n",
    "        _show_on_single_plot(axs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_genres_count = count_genres(mv.genres.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_org = mv.loc[mv['originals']==1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_org_genres_count = count_genres(mv_org.genres.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(16,8))\n",
    "bar = sns.barplot(x = 'counts',\n",
    "                  y = 'genres',\n",
    "                  data = mv_genres_count,\n",
    "                  ax = ax[0],\n",
    "                  orient = 'h')\n",
    "show_values_on_bars(bar, h_v='h', space=0.3)\n",
    "ax[0].set_title('The distribution of Netflix movies')\n",
    "\n",
    "bar = sns.barplot(x = 'counts',\n",
    "                  y = 'genres',\n",
    "                  data = mv_org_genres_count,\n",
    "                  ax = ax[1],\n",
    "                  orient = 'h')\n",
    "show_values_on_bars(bar, h_v='h', space=0.3)\n",
    "ax[1].set_title('The distribution of Netflix Originals movies')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nomalise the data and compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_genres_count['percentage'] = mv_genres_count['counts'].apply(lambda x: round(x/genres_df.counts.sum(),2))\n",
    "mv_org_genres_count['percentage'] = mv_org_genres_count['counts'].apply(lambda x: round(x/genres_df.counts.sum(),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(16,8))\n",
    "bar = sns.barplot(x = 'percentage',\n",
    "                  y = 'genres',\n",
    "                  data = mv_genres_count,\n",
    "                  ax = ax[0],\n",
    "                  orient = 'h')\n",
    "# show_values_on_bars(bar, h_v='h', space=0.3)\n",
    "ax[0].set_title('The distribution of Netflix movies')\n",
    "\n",
    "bar = sns.barplot(x = 'percentage',\n",
    "                  y = 'genres',\n",
    "                  data = mv_org_genres_count,\n",
    "                  ax = ax[1],\n",
    "                  orient = 'h')\n",
    "# show_values_on_bars(bar, h_v='h', space=0.3)\n",
    "ax[1].set_title('The distribution of Netflix Originals movies')\n",
    "plt.savefig('movie%.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trend_in_yearN(df ,genre , N):\n",
    "    \"\"\"\n",
    "    return how many title's are in the given genre in the given year.\n",
    "    \"\"\"\n",
    "    x = count_genres(df.loc[df['year']== N].genres.values.tolist())\n",
    "    return x.set_index('genres').loc[genre].values.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ten_year_trend(df, genre, s=2010, e=2020):\n",
    "    \"\"\"\n",
    "    default setting start with 2010 end with 2019 (10 years).\n",
    "    return a dictionary\n",
    "    \"\"\"\n",
    "    trend = defaultdict(int)\n",
    "    for key in range(s, e):\n",
    "        year = str(key)\n",
    "        trend[key] = trend_in_yearN(mv, genre, year)\n",
    "    return trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com = ten_year_trend(mv, 'comedy')\n",
    "sns.lineplot(x = list(com.keys()),\n",
    "            y = list(com.values()),\n",
    "            marker = 'X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trend_dataframe(df, cols):\n",
    "    \"\"\"\n",
    "    df = from which df to produce ten_year_trend\n",
    "    cols = list of genres you want to include\n",
    "    \"\"\"\n",
    "    trend_df = pd.DataFrame()\n",
    "    for genre in cols:\n",
    "        temp = pd.DataFrame(data=[ten_year_trend(df, genre)]).transpose().rename(columns={0:genre})\n",
    "        trend_df = pd.concat([trend_df, temp], axis=1)\n",
    "    return trend_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['drama','comedy','action-and-adventure','thriller','romance',\n",
    "        'mystery', 'documentary','crime','family','fantasy']\n",
    "trend_df = pd.DataFrame()\n",
    "for genre in cols:\n",
    "    temp = pd.DataFrame(data=[ten_year_trend(mv, genre)]).transpose().rename(columns={0:genre})\n",
    "    trend_df = pd.concat([trend_df, temp], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_trend_dataframe(mv, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = trend_df.columns.values.tolist()[1:6]\n",
    "for gen in genres:\n",
    "    sns.lineplot(x = 'index', y = gen, data = trend_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TVshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_csv('finaldataset_v3.csv', usecols=['title','genres','year','type','originals','cleaned'])\n",
    "tv = temp.loc[temp['type']=='tvshow'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_genres_count = count_genres(tv.genres.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_org = tv.loc[tv['originals']==1].copy()\n",
    "tv_org_genres_count = count_genres(tv_org.genres.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(16,8))\n",
    "bar = sns.barplot(x = 'percentage',\n",
    "                  y = 'genres',\n",
    "                  data = tv_genres_count,\n",
    "                  ax = ax[0],\n",
    "                  orient = 'h')\n",
    "# show_values_on_bars(bar, h_v='h', space=0.3)\n",
    "ax[0].set_title('The distribution of Netflix Tvshow')\n",
    "\n",
    "bar = sns.barplot(x = 'percentage',\n",
    "                  y = 'genres',\n",
    "                  data = tv_org_genres_count,\n",
    "                  ax = ax[1],\n",
    "                  orient = 'h')\n",
    "# show_values_on_bars(bar, h_v='h', space=0.3)\n",
    "ax[1].set_title('The distribution of Netflix Originals Tvshow')\n",
    "plt.savefig('tvshow%.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_trend = create_trend_dataframe(tv, cols).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = tv_trend.columns.values.tolist()[1:10]\n",
    "for gen in genres:\n",
    "    sns.lineplot(x = 'index', y = gen, data = tv_trend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
